---
title: Participant Specific Model analyses to crossed-hands data
author: "Kaian Unwalla"
date: "November, 2021"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

This code uses a Bayesian maximum likelihood estimation to separately estimate the internal and external weights for each participant. The model works by finding the most likely slope for each psychometric curve. 
Based on the prevailing theory for the crossed-hands deficit the model calculates the slopes for each condition as following:
- For the uncrossed curves: the slope is estimated as internal weight + external weight
- For the crossed curves: the slope is estimated as internal weight - external weight
This results in a single internal weight and external weight that is estimating the slope for both the crossed and uncrossed curves. 
- For more detail see: Unwalla, K., Goldreich, D., & Shore, D. I. (2021). Exploring reference frame integration using response demands in a tactile temporal-order judgement task. Multisensory Research, 34(8), 807-838.

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.align = 'center', fig.path='Figs/',
                      echo=FALSE, warning=FALSE, message=FALSE, include = TRUE)
```

```{r, libraries}
rm(list=ls())
library(tidyverse)
library(tidyfst)

source("Model functions.R")


time<-format(Sys.time(),"%b%d_%H%M%S")

path = 'Data/'
alldata1 <- read.table(paste(path,'Test Data.txt', sep = ""), header = T)

saveData = TRUE

```

```{r, participant-specific_model}
#choose the range of weights you want tested
minWeight = 0 
maxWeight = 20

#Calculates the normalized likelihood values for each internal and external weight combination
NormMLE <- calc.MLE(alldata1, minWeight, maxWeight, 0.5)

#Calculates the maximum likelihood weight pair
MLE <- max.MLE(NormMLE)

if(saveData){
  saveRDS(NormMLE, file = paste(path,"NormLikelihoods.rds", sep=""), compress = "xz")
  saveRDS(MLE, file = paste(path,"MaxLikelihoods.rds", sep=""), compress = "xz")
}
```


## Visualizations

This code creates intensity plots for each participant, which visually represents the likelihood of each hypothesis. The darker the points represent higher likelihood hypotheses. The light coloured circle represents the maximum likelihood estimate. 
```{r, MLE_intensity_plots}
#Creates intensity plots where darker colours indicate more likely weight combinations for each participant
NormMLE %>%
  ggplot(aes(wInt,wExt, fill = Condition, alpha=Likelihood))+
  guides(alpha=FALSE)+
  geom_tile()+
  scale_alpha_continuous(range = c(0,1))+
  xlab('Internal Weight')+ylab('External Weight')+
  facet_wrap(~Participant, ncol = 5)+
  geom_point(data = MLE, mapping = aes(x = wInt, y = wExt, color = Condition))+  #this plots the maximum likelihood as a point
  scale_fill_manual(values = c('black','blue'))+
  scale_color_manual(values = c('grey', 'light blue'))
```

This provides a visualization of how the weights change in response to the changed condition for each participant
```{r MLE_participant_weights}
MLE %>% 
  ggplot(aes(x=wInt, y=wExt, fill=Condition))+
  geom_point(size = 5, shape=21)+
  geom_path(arrow=arrow(type = 'closed',length = unit(0.3, "cm"), ends = 'first'), 
            size = 0.5, alpha = 0.3, aes(group=Participant), 
            show.legend = FALSE)+  #hide arrow symbol from legend
  scale_fill_manual(values = c('black','blue'))+
  xlim(minWeight,maxWeight)+ylim(minWeight,maxWeight)+
  ylab('External Weight')+xlab("Internal Weight")
```

Here we are comparing the weights predicted by the MLE to the true weights used to create the data. This allows us to get a better understanding on whether the model and the MLE are settling near the true weights (a sign the model works). 
```{r, real_vs_estimated_weights}
#summarize the true weights of each participant
trueWeights <- alldata1 %>% 
  group_by(Participant,Condition) %>% 
  summarize(wInt = mean(wInt), wExt = mean(wExt), Likelihood = 2) #setting a dummy likelihood to easily group the data in the graph

rbind(trueWeights, MLE) %>% 
  ggplot(aes(x = wInt, y = wExt))+
  geom_path(aes(group = Participant), color = 'grey')+
  geom_point(aes(color = as.character(Likelihood)), size = 2)+
  xlab("Internal Weight")+ylab("External Weight")+
  scale_color_manual(values = c('black','grey'), labels = c("Estimated Weight", "True Weight"))+
  facet_wrap(~Condition)
```
- The model does a decent job estimating the participant weights, but reveals two issues:
- First: the model tends to over-estimates the weights. 
- Second: the model estimated the weights more accurately in condition A. 
- Both these factors are likely the result of the requirement to find a slope that works for both the crossed and uncrossed curves, and as performance improves it provides many more weights that can accurately fit the data. 

Another way to see how similar the model output is to the true data, is to look at a measure that wasn't directly measured by the model. Here I have used the PCD score. By calculating the PCD score based on the estimated data and comparing it to the true data we can see how well the model output maps onto the data. 
```{r, MLE_actual_vs_modelPCD}
#this calculates a PCD score based on the predicted data and summarizes the participants actual PCD score
modelPCD <- full_join(Pivot(alldata1), MLE) %>% 
  mutate(Estimated = genHypothesisMLE(wInt,wExt,Hands,SOA,Condition)) %>% 
  gather(Type, pRfirst, Data,Estimated) %>% 
  select(-numTrials,-numRF) %>% 
  spread(key= Hands, pRfirst) %>% 
  group_by(Type,Participant,Condition) %>% 
  mutate(PCD = ifelse(SOA < 0, (Crossed - Uncrossed),(Uncrossed - Crossed))) %>% 
  summarize(PCD = sum(PCD)) %>% 
  ungroup() %>% 
  spread(key=Type,PCD)


#plots participants actual PCD score with their predicted PCD score
modelPCD %>% 
  ggplot(aes(x=Data, y=Estimated))+
  geom_point(size = 3, shape = 21, aes(fill = Condition))+
  scale_fill_manual(values = c('black','blue'))+
  xlim(0,5.5)+ylim(0,5.5)+
  geom_abline(slope = 1, intercept = 0)+
  ylab('Estimated PCD')+xlab("True PCD")
```
- Here we have the true PCD score on the x-axis and the model estimated PCD on the y-axis. I have plotted a straight line with a slope of 1, going through the origin. The closer the points fall to this line, the more similar the model output to the data. We can see that the model is actually doing a good job at estimating the PCD scores. 

